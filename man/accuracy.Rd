% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/accuracy.R
\name{accuracy}
\alias{accuracy}
\title{Model Accuracy}
\usage{
accuracy(x, known)
}
\arguments{
\item{x}{The model classification \code{\link[base]{list}}/\code{\link[base]{vector}}
(typically the results of \code{classify}).}

\item{known}{The known expert coded \code{\link[base]{list}}/\code{\link[base]{vector}} of outcomes.}
}
\value{
Returns a list of five elements:
\item{exact.in}{A numeric vector between 0-1 (0 no match; 1 perfect match) comparing \code{x} to \code{known} for exact matching.}
\item{any.in}{A numeric vector between 0-1 (0 no match; 1 perfect match) comparing \code{x} to \code{known} for non-location specific matching (\code{\%in\%} is used).  This ignores the differences in length between \code{x} and \code{known}.}
\item{logical.in}{A logical version of \code{exact} with \code{TRUE} being equal to 1 and all else being \code{FALSE}.  This can be used to locate perfect and/or non matches.}
\item{exact}{The proportion of the vector of tags in \code{x} matching \code{known} exactly.}
\item{ordered}{The proportion of the elements of tags in \code{x} matching \code{known} exactly (order matters).}
\item{adjusted}{An adjusted mean score of \code{ordered} and \code{unordered}.}
\item{unordered}{The proportion of the elements of tags in \code{x} matching \code{known} exactly regardless of order.}
}
\description{
Check a model's tagging/categorizing accuracy against known expert coded
outcomes.
}
\examples{
known <- list(1:3, 3, NA, 4:5, 2:4, 5, integer(0))
tagged <- list(1:3, 3, 4, 5:4, c(2, 4:3), 5, integer(0))
accuracy(tagged, known)

## Examples
library(dplyr)
data(presidential_debates_2012)

discoure_markers <- list(
    response_cries = c("oh", "ah", "aha", "ouch", "yuk"),
    back_channels = c("uh[- ]huh", "uhuh", "yeah"),
    summons = "hey",
    justification = "because"
)

## Only Single Tag Allowed Per Text Element
mod1 <- presidential_debates_2012 \%>\%
    with(., term_count(dialogue, TRUE, discoure_markers)) \%>\%
    classify()

fake_known <- mod1
set.seed(1)
fake_known[sample(1:length(fake_known), 300)] <- "random noise"

accuracy(mod1, fake_known)

## Multiple Tags Allowed
mod2 <- presidential_debates_2012 \%>\%
    with(., term_count(dialogue, TRUE, discoure_markers)) \%>\%
    classify(n = 2)

fake_known2 <- mod2
set.seed(30)
fake_known2[sample(1:length(fake_known2), 500)] <- c("random noise", "back_channels")

accuracy(mod2, fake_known2)
}
\keyword{accuracy}
\keyword{fit}
\keyword{model}

